{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fbeb9b4a-324f-45bc-830f-aba080c7a961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as ss\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import fsolve\n",
    "from scipy.optimize import brentq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edea99c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price for zero-coupon bond with stochastic interest rate under Vasicek's model\n",
    "def ZC_Vasicek(F, r, kappa, theta, sigma, t, T):\n",
    "    \n",
    "    delta_T = T - t\n",
    "    \n",
    "    B = (1 - np.exp(-kappa * delta_T)) / kappa\n",
    "    \n",
    "    A = np.exp((theta - (sigma**2) / (2 * kappa**2)) * (B - delta_T) - (sigma**2 / (4 * kappa)) * B**2)\n",
    "    \n",
    "    bond_price = F * A * np.exp(-B * r)\n",
    "    \n",
    "    return bond_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "929340d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.97852638018804\n"
     ]
    }
   ],
   "source": [
    "print(ZC_Vasicek(F=100, r=0.02, kappa = 0.1, theta = 0.03, sigma=0.02, t=0, T=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09444e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rpoi(a, y, lam, t, T):\n",
    "    return np.exp(lam * (T-t) * (np.exp(a) - 1) - a * y)\n",
    "\n",
    "def rlog(a, y, mu, sig, n):\n",
    "    # Calculate the exponents\n",
    "    exponent1 = ((mu + a)**2 - mu**2) / (2 * sig**2)\n",
    "    exponent2 = a * y / (sig**2)\n",
    "    \n",
    "    # Compute the final result using logarithms to avoid overflow\n",
    "    log_result = (exponent1 * n) - exponent2  # Logarithmic equivalent of the division\n",
    "    \n",
    "    # Calculate the result using np.exp\n",
    "    result = np.exp(log_result)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def g(b=0.07,lam=35,D=9000000000,T=1, mu=18.4, sig=1):\n",
    "    lhs = 2 * lam * T * b / sig**2 * np.exp(b**2 / (2 * sig**2))\n",
    "    z = (np.log(D) - mu + b) / sig\n",
    "    rhs = norm.pdf(z) / (sig * norm.sf(z))\n",
    "    return lhs - rhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a872ab74-103b-4f86-b5eb-a5f09887fc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MC with lognormal distribution for the size of losses\n",
    "def naive_MC_log(nr, lam, D, mu, sig, T):\n",
    "    h = []\n",
    "    poissons = np.random.poisson(lam=lam*T, size=nr)\n",
    "    for i in range(nr):\n",
    "        x = np.sum(np.random.lognormal(mean=mu, sigma=sig, size = poissons[i]))\n",
    "        h.append(int(x>D))\n",
    "    return np.cumsum(h)/np.arange(1,nr+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7793a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance sampling for default probability\n",
    "def MC_IS_log_poi(nr=5000, lam=35,D=9000000000, mu=18.4, sig=1, t=0, T=1):\n",
    "   \n",
    "    def root_func(b):\n",
    "        return g(b, lam, D, T, mu, sig)\n",
    "        \n",
    "    # Initial variables\n",
    "    #a_log = fsolve(root_func, x0=0.05)[0]\n",
    "    a_log = brentq(g, 0.001, 0.2)\n",
    "    a_poi = a_log**2/(2*sig**2)\n",
    "    poisson_means = lam * T * np.exp(a_poi)\n",
    "    new_mu = mu+a_log\n",
    "\n",
    "    # Preallocate memory for cumulative sums\n",
    "    h = np.zeros(nr)\n",
    "    r_poi = np.zeros(nr)\n",
    "    r_log = np.zeros(nr)\n",
    "    \n",
    "    # Loop over the number of simulations\n",
    "    for i in range(nr):\n",
    "        # Generate Poisson-distributed count\n",
    "        poissons = np.random.poisson(lam=poisson_means)\n",
    "\n",
    "        # Generate the exponential random variables for this count\n",
    "        # Directly sum them without creating large intermediate arrays\n",
    "        x = np.random.normal(loc=new_mu, scale=sig, size=poissons)\n",
    "        y = np.sum(x)\n",
    "        z = np.sum(np.exp(x))\n",
    "\n",
    "        # Compute h and r for this simulation\n",
    "        h[i] = int(z > D)\n",
    "        r_poi[i] = rpoi(a_poi, poissons, lam, t, T)\n",
    "        r_log[i] = rlog(a_log, y, mu, sig, poissons)\n",
    "\n",
    "    # Calculate cumulative sum and return the average at each step\n",
    "    cumulative_sum = np.cumsum(h * r_poi * r_log)\n",
    "    cumulative_avg = cumulative_sum / np.arange(1, nr + 1)\n",
    "\n",
    "    return cumulative_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "16ca93d7-8987-4ae6-8d1d-24570f778eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-coupon CAT bond pricing\n",
    "def CAT_ZC_Vasicek(F, r, kappa, theta, sigma, D, lam, mu, sig, nr, t, T):\n",
    "    if lam * T * np.exp(mu + sig**2 / 2) < D:\n",
    "        price = ZC_Vasicek(F, r, kappa, theta, sigma, t, T)*(1-MC_IS_log_poi(nr, lam, D, mu, sig, t, T)[-1])\n",
    "    else:  # Case: N == 0 and lam * T * k * th > D\n",
    "        price = ZC_Vasicek(F, r, kappa, theta, sigma, t, T)*(1-naive_MC_log(nr, lam, D, mu, sig, T)[-1])\n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "70310a9a-04c9-4b74-8a4e-79cdd6435090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.9286478733177\n"
     ]
    }
   ],
   "source": [
    "print(CAT_ZC_Vasicek(F=100, r=0.02, kappa=0.1, theta=0.03, sigma=0.02, lam=35, D=9000000000, mu=18.4, sig=1, nr=5000, t=0, T=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31c61977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAT bond with coupons pricing\n",
    "def CAT_C_Vasicek(F, c, r, kappa, theta, sigma, D, lam, mu, sig, nr, t, N, T):\n",
    "    c_sum = 0\n",
    "    dt = T/N\n",
    "    \n",
    "    for coupon_count in range (N):\n",
    "        if lam * (coupon_count+1) * dt * np.exp(mu + sig**2 / 2) < D:\n",
    "            c_sum += ZC_Vasicek(F*c, r, kappa, theta, sigma, t, T=(coupon_count+1)*dt)*(1-MC_IS_log_poi(nr, lam, D, mu, sig, t, T=(coupon_count+1)*dt)[-1])\n",
    "        else:  # Case: N == 0 and lam * T * k * th > D\n",
    "            c_sum += ZC_Vasicek(F*c, r, kappa, theta, sigma, t, T=(coupon_count+1)*dt)*(1-naive_MC_log(nr, lam, D, mu, sig, T=(coupon_count+1)*dt)[-1])\n",
    "    \n",
    "    if lam * T * np.exp(mu + sig**2 / 2) < D:\n",
    "        c_sum = c_sum + ZC_Vasicek(F, r, kappa, theta, sigma, t, T)*(1-MC_IS_log_poi(nr, lam, D, mu, sig, t, T)[-1])\n",
    "    else:  # Case: N == 0 and lam * T * k * th > D\n",
    "        c_sum = c_sum + ZC_Vasicek(F, r, kappa, theta, sigma, t, T)*(1-naive_MC_log(nr, lam, D, mu, sig, T)[-1])\n",
    "    \n",
    "    return c_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f5b3f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109.3034976483269\n"
     ]
    }
   ],
   "source": [
    "print(CAT_C_Vasicek(F=100, c=0.05, r=0.02, kappa=0.1, theta=0.03, sigma=0.02, lam=35,D=9000000000, mu=18.4, sig=1, nr=5000, t=0, N=3, T=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d5bac6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter ranges\n",
    "F = 1000  # Fixed face value\n",
    "t = 0     # Fixed initial time\n",
    "#lam = 1   # Fixed Poisson rate\n",
    "mu = 18.4    # Fixed lognormal shape\n",
    "sig = 1    # Fixed lognormal scale\n",
    "nr = 5000\n",
    "c=0.05\n",
    "#r=0.03\n",
    "kappa=0.2\n",
    "theta=0.03\n",
    "sigma=0.02\n",
    "\n",
    "\n",
    "\n",
    "# lam_values = np.linspace(30, 40, 50)       # Range for lambda\n",
    "# D_values = np.linspace(7, 11, 21)*1000000000           # Range for threshold\n",
    "# N_values = [2, 4, 6, 12]      # Range for coupon frequency\n",
    "# T_values = np.linspace(90, 720, 43)*1/360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "274a1c78-9069-43dd-bc73-098b9d5e25d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 600000 simulations in 60 chunks...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk 1/60: 100%|██████████████| 10000/10000 [30:41<00:00,  5.43it/s]\n",
      "Processing chunk 2/60: 100%|██████████████| 10000/10000 [30:10<00:00,  5.52it/s]\n",
      "Processing chunk 3/60: 100%|██████████████| 10000/10000 [30:16<00:00,  5.51it/s]\n",
      "Processing chunk 4/60: 100%|██████████████| 10000/10000 [30:29<00:00,  5.47it/s]\n",
      "Processing chunk 5/60: 100%|██████████████| 10000/10000 [30:35<00:00,  4.23s/it]\n",
      "Processing chunk 6/60: 100%|██████████████| 10000/10000 [30:50<00:00,  5.40it/s]\n",
      "Processing chunk 7/60: 100%|██████████████| 10000/10000 [30:13<00:00,  5.51it/s]\n",
      "Processing chunk 8/60: 100%|██████████████| 10000/10000 [29:52<00:00,  5.58it/s]\n",
      "Processing chunk 9/60: 100%|██████████████| 10000/10000 [29:58<00:00,  5.56it/s]\n",
      "Processing chunk 10/60: 100%|█████████████| 10000/10000 [30:09<00:00,  5.53it/s]\n",
      "Processing chunk 11/60: 100%|█████████████| 10000/10000 [30:22<00:00,  5.49it/s]\n",
      "Processing chunk 12/60: 100%|█████████████| 10000/10000 [30:20<00:00,  5.49it/s]\n",
      "Processing chunk 13/60: 100%|█████████████| 10000/10000 [30:04<00:00,  5.54it/s]\n",
      "Processing chunk 14/60: 100%|█████████████| 10000/10000 [29:46<00:00,  5.60it/s]\n",
      "Processing chunk 15/60: 100%|█████████████| 10000/10000 [29:45<00:00,  5.60it/s]\n",
      "Processing chunk 16/60: 100%|█████████████| 10000/10000 [30:38<00:00,  5.44it/s]\n",
      "Processing chunk 17/60: 100%|█████████████| 10000/10000 [31:17<00:00,  5.33it/s]\n",
      "Processing chunk 18/60: 100%|█████████████| 10000/10000 [30:58<00:00,  5.38it/s]\n",
      "Processing chunk 19/60: 100%|█████████████| 10000/10000 [30:51<00:00,  5.40it/s]\n",
      "Processing chunk 20/60: 100%|█████████████| 10000/10000 [30:36<00:00,  5.44it/s]\n",
      "Processing chunk 21/60: 100%|█████████████| 10000/10000 [31:02<00:00,  5.37it/s]\n",
      "Processing chunk 22/60: 100%|█████████████| 10000/10000 [30:46<00:00,  5.42it/s]\n",
      "Processing chunk 23/60: 100%|█████████████| 10000/10000 [30:05<00:00,  5.54it/s]\n",
      "Processing chunk 24/60: 100%|█████████████| 10000/10000 [30:20<00:00,  5.49it/s]\n",
      "Processing chunk 25/60: 100%|█████████████| 10000/10000 [30:33<00:00,  5.45it/s]\n",
      "Processing chunk 26/60: 100%|█████████████| 10000/10000 [29:53<00:00,  5.58it/s]\n",
      "Processing chunk 27/60: 100%|█████████████| 10000/10000 [31:18<00:00,  5.32it/s]\n",
      "Processing chunk 28/60: 100%|█████████████| 10000/10000 [31:32<00:00,  5.28it/s]\n",
      "Processing chunk 29/60: 100%|█████████████| 10000/10000 [31:15<00:00,  5.33it/s]\n",
      "Processing chunk 30/60: 100%|█████████████| 10000/10000 [30:45<00:00,  5.42it/s]\n",
      "Processing chunk 31/60: 100%|█████████████| 10000/10000 [30:26<00:00,  5.47it/s]\n",
      "Processing chunk 32/60: 100%|█████████████| 10000/10000 [30:13<00:00,  5.51it/s]\n",
      "Processing chunk 33/60: 100%|█████████████| 10000/10000 [30:38<00:00,  5.44it/s]\n",
      "Processing chunk 34/60: 100%|█████████████| 10000/10000 [30:33<00:00,  5.45it/s]\n",
      "Processing chunk 35/60: 100%|█████████████| 10000/10000 [30:30<00:00,  5.46it/s]\n",
      "Processing chunk 36/60: 100%|█████████████| 10000/10000 [30:46<00:00,  5.42it/s]\n",
      "Processing chunk 37/60: 100%|█████████████| 10000/10000 [30:30<00:00,  5.46it/s]\n",
      "Processing chunk 38/60: 100%|█████████████| 10000/10000 [30:25<00:00,  5.48it/s]\n",
      "Processing chunk 39/60: 100%|█████████████| 10000/10000 [30:18<00:00,  5.50it/s]\n",
      "Processing chunk 40/60: 100%|█████████████| 10000/10000 [30:05<00:00,  5.54it/s]\n",
      "Processing chunk 41/60: 100%|█████████████| 10000/10000 [30:10<00:00,  5.52it/s]\n",
      "Processing chunk 42/60: 100%|█████████████| 10000/10000 [30:05<00:00,  5.54it/s]\n",
      "Processing chunk 43/60: 100%|█████████████| 10000/10000 [30:21<00:00,  5.49it/s]\n",
      "Processing chunk 44/60: 100%|█████████████| 10000/10000 [30:40<00:00,  5.43it/s]\n",
      "Processing chunk 45/60: 100%|█████████████| 10000/10000 [30:24<00:00,  5.48it/s]\n",
      "Processing chunk 46/60: 100%|█████████████| 10000/10000 [30:29<00:00,  5.47it/s]\n",
      "Processing chunk 47/60: 100%|█████████████| 10000/10000 [30:19<00:00,  5.50it/s]\n",
      "Processing chunk 48/60: 100%|█████████████| 10000/10000 [30:27<00:00,  5.47it/s]\n",
      "Processing chunk 49/60: 100%|█████████████| 10000/10000 [30:26<00:00,  5.48it/s]\n",
      "Processing chunk 50/60: 100%|█████████████| 10000/10000 [30:29<00:00,  5.47it/s]\n",
      "Processing chunk 51/60: 100%|█████████████| 10000/10000 [30:41<00:00,  5.43it/s]\n",
      "Processing chunk 52/60: 100%|█████████████| 10000/10000 [30:31<00:00,  5.46it/s]\n",
      "Processing chunk 53/60: 100%|█████████████| 10000/10000 [30:15<00:00,  5.51it/s]\n",
      "Processing chunk 54/60: 100%|█████████████| 10000/10000 [30:43<00:00,  5.42it/s]\n",
      "Processing chunk 55/60: 100%|█████████████| 10000/10000 [30:43<00:00,  5.42it/s]\n",
      "Processing chunk 56/60: 100%|█████████████| 10000/10000 [30:44<00:00,  5.42it/s]\n",
      "Processing chunk 57/60: 100%|█████████████| 10000/10000 [31:03<00:00,  5.37it/s]\n",
      "Processing chunk 58/60: 100%|█████████████| 10000/10000 [30:53<00:00,  5.40it/s]\n",
      "Processing chunk 59/60: 100%|█████████████| 10000/10000 [30:24<00:00,  5.48it/s]\n",
      "Processing chunk 60/60: 100%|█████████████| 10000/10000 [30:14<00:00,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation complete. Results saved to CSV file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import csv\n",
    "\n",
    "N_sim = 600000\n",
    "N_values = [0, 2, 3, 4, 6, 8, 10, 12]\n",
    "chunk_size = 10000  \n",
    "start_chunk = 1  # Allows skipping initial chunks\n",
    "\n",
    "# Compute total chunks\n",
    "total_chunks = (N_sim) // chunk_size\n",
    "results = []\n",
    "\n",
    "# CSV file path\n",
    "csv_file = 'CAT_price_log.csv'\n",
    "\n",
    "# Prepare CSV file header if needed\n",
    "csv_header = [\"c\", \"r\", \"kappa\", \"theta\", \"sigma\", \"lambda\", \"D\", \"N\", \"T\", \"Price\"]\n",
    "\n",
    "# Open CSV file in write mode to create the header\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(csv_header)  # Write the header to the CSV file\n",
    "    \n",
    "    print(f\"Running {N_sim} simulations in {total_chunks} chunks...\\n\")\n",
    "\n",
    "    for chunk_index in range(1, total_chunks + 1):\n",
    "        if chunk_index < start_chunk:\n",
    "            continue  # Skip initial chunks if needed\n",
    "\n",
    "        chunk_results = []\n",
    "\n",
    "        for _ in tqdm(range(chunk_size), desc=f\"Processing chunk {chunk_index}/{total_chunks}\"):\n",
    "            N = np.random.choice(N_values)  # Randomly select N\n",
    "            r = np.random.uniform(0, 0.08)\n",
    "            lam = np.random.uniform(30, 40)\n",
    "            D = np.random.uniform(7, 13)*1000000000 \n",
    "            T = np.random.uniform(90, 720)*1/360\n",
    "\n",
    "            # Condition to determine which function to use\n",
    "            if N == 0:\n",
    "                price = CAT_ZC_Vasicek(F, r, kappa, theta, sigma, D, lam, mu, sig, nr, t, T)\n",
    "            else:\n",
    "                price = CAT_C_Vasicek(F, c, r, kappa, theta, sigma, D, lam, mu, sig, nr, t, N, T)\n",
    "\n",
    "            chunk_results.append({\n",
    "                \"c\": c,\n",
    "                \"r\": r,\n",
    "                \"kappa\": kappa,\n",
    "                \"theta\": theta,\n",
    "                \"sigma\": sigma,\n",
    "                \"lambda\": lam,\n",
    "                \"D\": D,\n",
    "                \"N\": N,\n",
    "                \"T\": T,\n",
    "                \"Price\": price\n",
    "            })\n",
    "\n",
    "        # Save the chunk results into the CSV file after each chunk finishes\n",
    "        for result in chunk_results:\n",
    "            writer.writerow(result.values())\n",
    "\n",
    "        results.extend(chunk_results)  # Save chunk results\n",
    "\n",
    "\n",
    "print(\"Simulation complete. Results saved to CSV file.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d9798b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826e5830",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
